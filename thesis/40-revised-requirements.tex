% !TEX root = thesis.tex
\documentclass[thesis.tex]{subfiles} 
\begin{document}

\chapter{Revised Requirements}
\label{chap:revised}
In this chapter we will analyze which parts of our exploratory prototype we can
utilize in our implementation. To that end we will examine every tool used and
arrive at a subset of these tools, which we will complement with a fresh set of
parts. Our goal is to have a plan laid out for the final architecture at the end
of this chapter.

The prototype featured a large amount of moving parts that were constructed for
the occasion. Among others this includes our templates, that were not mustache
templates but simple repeatable patterns in PHP. The recursive tree parser,
building a set of models and views for us to use on the client-side is another
example of an ad-hoc constructed tool.

These parts bring with them their own set of problems and bugs.
Since they are custom developed in a limited time frame they will have coding
errors other seasoned related tools do not have.
We decided to develop these tools for our prototype regardless,
because evaluating alternatives that would fit the purpose precisely
would have taken up more time.
This is not a sound strategy going forward. To implement our goal and later on
maintain it, we require a nucleus of code, which only incorporates the parts
that are necessary and unique to our solution.
Succinctly put: There is no reason to reinvent the wheel.
Most of these parts have nothing to do directly with the concept of this thesis.
They are rather tools that help achieve the goals of it.
For a proper tool, that we can consider usable, to emerge from our process,
we will need to reduce the amount of said custom parts.
To that end we will first have to identify the superfluous parts of the
prototype, that can be replaced by existing well maintained tools. Once we have
achieved this, we can begin concentrating on the core of our concept and define
it with greater precision.

\section{Revised Goal}
\label{sec:revised-goal}
In chapter \ref{chap:requirements} we concluded that our goal is to retrieve
information about the binding of model fields to placeholders in templates and
use this information to bind client-side models to the DOM.

In reality this goal consists of two parts:\
First we need to extract the dataset passed into the template engine together
with the template from the rendered template\footnote{Read: from the HTML in the
browser.}.
In the prototype we did this by utilizing hard-coded XPaths. The motivation
behind hard-coding this part was the assumption that we would generate the those
paths dynamically in our real implementation.\
Once the dataset is rebuilt the second part consists of mapping its values
to models on the client-side. In the prototype we realized the mapping process
by hard-coding the types of backbone fields into the ModelView.\
However, our final implementation will only feature the first of these
processes.

To state it clearly:
\begin{quote}
Our goal is to extract the dataset passed to the mustache template engine from
the rendered template.
\end{quote}

This drastic change in course is grounded in the desire to create a tool that
is applicable in as many types of web applications as possible.
The mustache template engine is the only precondition for using the first part
of our mapping process. The second part however can have preconditions
other than backbone that were not explored in our prototype:\
To generate a mapping for client-side models, our tool will require to know the
origin of the values in the retrieved dataset\footnote{The dataset itself will
	contain only string values retrieved from the rendered template.
	Its structure can similarly only resemble the structure of the template.}.
These values usually originate in models on the server-side\footnote{They
	may also come from client-side models, where the mapping would make less
	sense, because the retrieved values originates from these models.
	Section \ref{sec:two-way-binding} details why such a mapping would be
	advantageous regardless of that fact.}, where the developer may have chosen
from any number of server-side languages
and model frameworks. Unless we require the developer to specify the types and
relations between models in a format our tool can understand, we will have to
choose a language and model framework to automate this process. This choice
reduces the applicability of our tool greatly. Leaving only the option of
requiring the developer to specify the relations. For big web applications this
requirement may slow the development process significantly.
For this reason we choose to pursue only the first part of the mapping process.
With that choice the implementation will no longer concentrate on mapping values
sent by the server via rendered templates to client-side models,
but on extracting data from rendered templates.

By concentrating on one part of the process we are also able to create a tool in
the proper sense. As a guide for the properties of such a tool we can apply
some of the rules set by Eric Steven Raymond in his book
``The Art of Unix Programming''.
\begin{citequote}{\cite[Chapter 1]{UXART}}
\begin{itemize}
	\item Rule of Modularity: Write simple parts connected by clean interfaces.
	\item Rule of Clarity: Clarity is better than cleverness.
	\item Rule of Composition: Design programs to be connected to other programs.
	\item Rule of Separation: Separate policy from mechanism; separate interfaces from engines.
	\item Rule of Simplicity: Design for simplicity; add complexity only where you must.
	\item Rule of Parsimony: Write a big program only when it is clear by demonstration that nothing else will do.
	\item Rule of Transparency: Design for visibility to make inspection and debugging easier.
	\item Rule of Robustness: Robustness is the child of transparency and simplicity.
	\item Rule of Representation: Fold knowledge into data so program logic can be stupid and robust.
	\item Rule of Least Surprise: In interface design, always do the least surprising thing.
	\item Rule of Silence: When a program has nothing surprising to say, it should say nothing.
	\item Rule of Repair: When you must fail, fail noisily and as soon as possible.
	\item Rule of Economy: Programmer time is expensive; conserve it in preference to machine time.
	\item Rule of Generation: Avoid hand-hacking; write programs to write programs when you can.
	\item Rule of Optimization: Prototype before polishing. Get it working before you optimize it.
	\item Rule of Diversity: Distrust all claims for ``one true way''.
	\item Rule of Extensibility: Design for the future, because it will be here sooner than you think.
\end{itemize}
\end{citequote}

By focusing on data extraction we can follow the Rule of Composition more
easily: A layer to map the values we extract to client-side models can still be
implemented on top of it, thereby enabling developers to integrate our tool into
other client libraries than backbone.

The binding of models is a feature which would add to the complexity of our
tool. The tool still has a purpose and relevance without this
feature\footnote{This also means that we will no longer focus on the task from
	section \ref{sec:first-results} to couple server-side templates to ViewModels
	on the client-side.}.
We simplify our approach and thereby follow the Rule of Simplicity.

By following these rules we hope to be able to develop a tool that will be able
to fit into an ecosystem of existing software. To do this we focus on our
previously stated goal and remove all superfluous features that do not
contribute to that goal. There may later be feature additions that can help the
developer when writing software and lie in the functional scope of our tool.

\section{Simplifying the project}
\label{sec:simplifying}
Bear in mind that despite the following simplifications we may still use some
of the libraries.
As stated in the previous section, we intend our tool to perform in an ecosystem
of other software, minimizing dependencies can help developers integrate it into
their existing software without conflicts. As an example of such an ecosystem
consider Bower\footnote{\url{http://twitter.github.com/bower/}} by Twitter.
Bower is a package manager for client-side applications. It contains over 700
components ranging from asynchronous module
loaders\footnote{See section \ref{sec:requirejs}} to graphing libraries such
as ``d3''.

\subsection{Server-side}
\label{sec:simple-server}
We begin our simplification on the server. Here we communicated with a database
to persist our movies, actors etc. in the MySQL database. The database and the
object relational mapper (ORM) php-activerecord are not at all necessary for our
tool to work. They are interchangeable with any other type of software, that can
persist data on the server. Our concept should work with even ephemeral data.

Our server-side language of choice - PHP -, also belongs to this category.
The server could have been written in any other server-side language.
As a consequence, the template engine, will of course need to be
able to interface with that language. For the prototype we omitted these
templates and wrote them directly in PHP instead.

Our plan however is to write the server-side templates in mustache
(\ref{app:mustache}). Mustache is a template language that is very
predictable in its output, given that it cannot perform any computations on the
dataset or modify its input. This will be an advantage when we want to extract
values from rendered templates. Mustache also follows some of the rules set by
Terence Parr in his paper titled ``Enforcing Strict Model-View Separation in
Template Engines'' \cite{STRINGTPL}, which details how separating the
business-logic of a web application from the presentation layer is both
desirable and possible. One such rule states:
\begin{citequote}{\cite[Chapter 7]{STRINGTPL}}
	2. \textbf{the view cannot perform computations upon dependent data values}
	because the computations may change in the future and
	they should be neatly encapsulated in the model in any case.
	[...] the view cannot make assumptions about the meaning of data.
\end{citequote}
As noted above mustache does not support computations on data, which makes it
compatible with this rule\footnote{Although lambda sections
(\ref{app:mustache-lambda}) allow computations on data,
they cannot be considered \emph{embedded} computations,
since their functions are part of the dataset.
The authors sentiment (``they should be neatly encapsulated in the model'')
is therefore honored.}.

Another rule concerns the comparison of data:
\begin{citequote}{\cite[Chapter 7]{STRINGTPL}}
	3. \textbf{the view cannot compare dependent data values},
	but can test the properties of data such as presence/absence
	or length of a multi-valued data value.
\end{citequote}
Sections in mustache\footnote{See appendix \ref{app:mustache-section}} support
this exact behavior, save the length comparison.

Locating placeholders in templates and outputting their location is the solution
we proposed in the beginning of this thesis to the problem we identified with
server-side templates.
By extension, parsing server-side templates pertains to the core of our concept.
Since parsing arbitrary template syntaxes, would go out of the scope of this
thesis we must conclude that mustache belongs to the category of tools that
are essential.

\subsection{Client-side}
The client-side tools we have used in our prototype interact with the data we
``retrieved'' (remember: we did not actually retrieve any template information)
from the server. This makes the setup of the client more intricate. We will have
to look carefully at each tool and determine by the nature of its interaction
with that data, whether it is a crucial part of our concept.

Regardless of which tools we remove, we must remember that the information about
our server-side templates must be used somehow. This would suggest that the
client can have more than one structure and set of interconnected parts, which
leverage the additional information.

\begin{itemize}
\item Beginning with the periphery, we can easily see how a framework to ease
	the development of CSS is not part of our tool.
\item The JavaScript language is required on the basis that we need some form of
	client-side programming. We have discussed its alternatives in
	section \ref{sec:javascript-alts}, depending on the challenges we face in the
	implementation, we may choose a language which compiles to JavaScript instead.
\item underscore.js helps us to iterate through arrays and manage other
	operations more easily than in pure JavaScript. We can solve the same problems
	without it\footnote{although it may require more effort.}.
	This makes underscore.js a non-crucial part of our tool.
\item We use backbone.js to hold the values we retrieve from the DOM. The
	framework enables us to interact with these values. They can however also be
	modeled with simple JavaScript objects. Because of that backbone.js can not be
	considered a crucial part of our tool.
\end{itemize}

In essence we will not retain any client-side \emph{libraries}.

\end{document}
