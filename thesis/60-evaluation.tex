% !TEX root = thesis.tex
\documentclass[thesis.tex]{subfiles} 
\begin{document}

\chapter{Evaluation}
\label{chap:eval}
In this chapter we will analyze whether we achieved the goals we set ourselves.
We will also examine Comb in more detail to find potential for improvement and
uncover scenarios where Comb is not up to the task.

\section{Reviewing our goal}
In the requirements for the prototype (chapter \ref{chap:requirements})
we set out to couple the dataset fed into the server-side template engine with
the models on the client-side. In \ref{sec:revised-goal} we revised this
requirement by splitting the task into two distinct actions and changed the goal
to implementing the first part only: Extracting the dataset from a rendered
template.

The architecture we set to achieve this goal aimed at a two parted process where
we retrieve information from templates and later use that information to parse
rendered templates. The demo application\todo{-s ?} from chapter \ref{chap:demo}
integrates Comb to do exactly that. It renders a template with a custom dataset,
extracts the data from the rendered template and displays that data to the user.

\section{Pre-Parser tool improvements}
As with any piece of software, there is always room for improvement.
Comb is no different. In this section we will look at which parts of the
pre-parser can be improved.

\subsection{Parser}

\subsubsection{Extending the template grammar}
Looking at the Mustache-XML EBNF\footnote{figure \ref{fig:mustache-xml.ebnf}} we
can see how the grammar is simplistic, when compared with the
full XML \cite[section 2/\#sec-documents]{XMLSPEC} EBNF or to
HTML \cite{HTMLSPEC}\footnote{
	HTML 5 has no EBNF, the reason for that is detailed at
	\url{http://lists.w3.org/Archives/Public/www-tag/2009Sep/0013.html}
}. The intention is not to build a fully capable HTML parser, but the question
remains whether our grammar matches a superset which is generic enough to allow
for all templates that can be converted into a DOM. Among the possible problems
that may be encountered is namespacing of tag names. The \inline{identLetter}
\cite[\#v:identLetter]{PARSECDOC} property of our XML token parser in our
pre-parser tool lists the allowed letters in an identifier,
which in our case are xml tag names and attribute names. Among those letters is
the colon. This does however not guarantee a proper parsing of rendered
templates when querying the DOM with our client library.
\todo{Figure out if this works or not}

\subsubsection{Character references}
Character references are converted into characters by our parser and the
TagSoup library ostensibly contains a full lookup table of these references.
The recognition method of character references is unfortunately not very robust:
The user will be presented with a rather unhelpful error message if an ampersand
is not followed by a semicolon\footnote{
	i.e. the parser reaches at some point the end of the string and crashes
}. This issue can fortunately be corrected with some minor effort.
\todo{Fix comment recognition to at least not crash the parse ffs!}

\subsubsection{Standalone mustache tag lines}
As describe in \ref{sec:standalone-lines} mustache removes
lines containing only white space and a mustache section tag.
The demo application runs a modified version of mustache.js where this feature
is removed\footnote{
	Specifically we removed the highlighted line seen at
	\url{https://github.com/janl/mustache.js/blob/master/mustache.js\#L512}
}. Our parser does currently not account for this detail. This causes
our client library to expect a whitespace line where there is none.

\subsubsection{Mustache comments}
In \ref{sec:mustache-xml-ebnf} we deemed comments ``since it does not
output any content our client library can retrieve''. In \ref{sec:parent-nodes}
we introduced parent nodes into the dataset we return for variables.
This addition makes comments useful even though it does not output any data.
By placing comments in key locations in a template, the developer can access
nodes in a rendered template by referencing those comments and accessing their
parent node. Comments do however not contain identifiers but free form strings.
To simplify referencing we could consider anything up to a set of
separators as the identifier. The alternative would be to simply require the
developer to specify the entire string.

Although this feature addition can be considered a significant improvement to
the possibilities of our tool, it can not be considered a shortcoming.
Our goal was to retrieve the original dataset from a rendered template.
Comments do not receive any dataset value and do not output any value, as such
they were out of scope.

\subsection{Resolver}

\subsubsection{Identifier origins}
In section \ref{sec:arch-comp-tpl} we determined that we would not be able to
determine the origin of a key in the dataset precisely, when the context
stack is greater than one. This holds true for all cases except the inverted
section. The inverted section does not push a new context on top of our existing
context stack because it is only rendered when its identifier points at an empty
list\footnote{
	Or the data it points at is coerced into an empty list
} in the dataset. This is guaranteed by the specification\footnote{
	Read: ``This section MUST be rendered if and only if the data list is empty.''
}:
\begin{citequote}{\cite[inverted.yml]{MSTSPEC}}
This section MUST NOT be rendered unless the data list is empty.
\end{citequote}

We can be certain that all identifiers referenced in an inverted section do not
belong to the identifier of the section. This fact allows us to lift the parsed
values into the parent context.

\subsubsection{Lookahead}
\label{sec:lookahead}
The filter in our pre-parse tool currently requires mustache tags to be
separated by strings or XML tags. This restriction is necessary to ensure that
our client library can recognize the end of variables as well as the beginning
and end of section iterations. The parser employs a limited form of lookahead
when it checks whether an iteration is followed by another iteration. Variables
consider stop parsing as soon as they encounter the first occurrence of their
next sibling. This is a rather limiting restriction which can hinder developers
in writing templates.

We can overcome this restriction by enhancing the parsing capabilities of our
client library. From the pre-parser tool we only need to remove the
\emph{no\_lookahead} function located in the list of filters.

To create a simplistic form of lookahead we can catch errors thrown by
mustache tag objects when they are unable to verify their siblings and try
alternative possibilities until we succeed. This is however not only resource
intensive but may result a faulty dataset extraction, because more than one
combination of possibilities can be applied to a DOM tree.

A more sound approach requires extending our pre-parser tool as well. It can
combine the same aforementioned possibilities of parsing a template and replace
any unknowns (i.e. variables) with wildcard characters our client library can
recognize. Whether a section is entered is also not knowable when
analyzing a template, but we can create a binary tree of possibilities,
where each node represents a list of XML tags. Upon encountering a section we
branch and continue the tree generation. This tree generation can continue until
we encounter the end of a DOM tree. We can also set a limit on the depth of the
tree, thereby limiting the amount of possibilities our client library has to
try. Once the tree is generated the filter may analyze it and print errors if
two paths are indistinguishable. The tree can then be cut until the smallest
size without ambiguous paths is reached.

The client library can for example use this tree to determine whether a
section containing a variable as its first child and a variable as its
next sibling has another iteration by analyzing the content that follows this
ambiguity.

Such an improvement would also obsolete our filter that checks whether the
first child and next node of a section can be confused
(\emph{ambiguous\_boundaries}, section \ref{sec:filter}).

\subsubsection{Variable boundary ambiguity}
\label{sec:var-boundary-ambiguity}
Our lookahead improvement can not help alleviate a similar problems a developer
may encounter with two ore more variables in one text node as shown in figure 
\ref{fig:twovars-no-sep}.
\begin{figure}
	\centering
	\caption{Two variables without a separator between them}
	\label{fig:twovars-no-sep}
	\begin{subfigure}{\textwidth}
		\begin{lstlisting}[language=mustache]
<span>{{var_one}}{{var_two}</span>
		\end{lstlisting}
		\caption{Template}
		\label{fig:twovars-no-sep.mustache}
	\end{subfigure}
	
	\begin{subfigure}{\textwidth}
		\begin{lstlisting}[language=HTML]
<span>This text can be split between the two variables or belong to only one.</span>
		\end{lstlisting}
		\caption{Result}
		\label{fig:twovars-no-sep.html}
	\end{subfigure}
\end{figure}
The parser cannot split a string originating from two variables that are not
separated by text in any meaningful way. It is impossible to determine how much
text belongs to the first variable and how much text belongs to the second
variable\footnote{This also applies to more than two variables of course.}.

Separating variables with text can alleviate this problem only if the variable
values do not contain the separator itself. Consider the example in figure
\ref{fig:twovars-sep}, here the library cannot split the string in any
meaningful way either. We know that \inline{var\_two} at least contains
``slashes'', because there is no slash after the second variable in the
template. We can also determine that \inline{var\_one} at least contains
``path'', because we would see two subsequent slashes if \inline{var\_one} was
empty. Of the remaining slashes in the ``/with/multiple/'' string the
original separator can be any one of them.
\begin{figure}
	\centering
	\caption{Two variables separated with a `/'}
	\label{fig:twovars-sep}
	\begin{subfigure}{\textwidth}
		\begin{lstlisting}[language=mustache]
<a href="http://www.example.com/{{var_one}}/{{var_two}</a>
		\end{lstlisting}
		\caption{Template}
		\label{fig:twovars-sep.mustache}
	\end{subfigure}
	
	\begin{subfigure}{\textwidth}
		\begin{lstlisting}[language=HTML]
<a href="http://www.example.com/path/with/multiple/slashes</a>
		\end{lstlisting}
		\caption{Result}
		\label{fig:twovars-sep.html}
	\end{subfigure}
\end{figure}

\subsection{Filter}

\subsubsection{Suggestions}
Thanks to the Parsec library, the developer receives helpful messages when a
template cannot be parsed. Our filter component also outputs detailed error
messages. The errors can be improved by accompanying them with suggestions for
how to resolve them. Filters have access to enough information to calculate how
an error may be avoided.

\section{Client library improvements}

\subsubsection{Mustache tags as tag and attribute names}
In \ref{sec:template-constraints} listed the inability to specify mustache
tags in XML tag names and attribute names as a restriction on the templates our
tool can parse. We may however be able to allow this by changing our grammar and
modify our resolution phase to link mustache tags in a more generic way.
Our client library addresses DOM elements by child node indexes instead of tag
names and can therefore find these tags with no modifications. Tag names are
however used to determine various aspects of mustache tag boundaries. These
checks will have to be rewritten to allow for variable tag names.

\subsubsection{Fall back to lambda sections}
Lambda sections may currently cause unexpected errors in our client library.
It assumes every section is a normal section and throws errors if it does not
find what is expected to be found. Instead of stopping the parsing process
the client library should fall back to the assumption that the current section
is a lambda section and collect its contents. Similar to ambiguous variable
boundaries this strategy may be problematic as well. The parser can in many
cases not be sure when a lambda section is actually finished because its content
can vary wildly.

\subsubsection{Partials must be only children}
\label{sec:partial-only-child}
The filter of our pre-parser tool requires partials to be contained within an
XML tag as its only child. This is done to simplify the parsing process, which
would otherwise be complicated by accounting for siblings of root nodes in
a template.

\subsubsection{Unescaped variables as last children}
\label{sec:unescaped-variable-filter}
Much like lambda section the content of unescaped variables is hard to predict
and can be confused with the next sibling of the variable. We added the filter
\emph{unescaped\_pos} in the filter component of our pre-parser tool for that
reason. With the guarantee that an unescaped variable is always the last child
of an XML tag, our client library can add all nodes it encounters to the value
list of an unescaped variable beginnning at the location of that variable until
it finds no more nodes.

\subsubsection{Properties of values}
\label{sec:flatten-section}
When a property of an identifier is accessed, we know this identifier points at
an object rather than a list. If we in the same template encounter a section
using the same identifier, we can recreate the original dataset more precisely
by having the section return an object instead of a list with a single item
containing that object.

\subsubsection{Improving the retrieved dataset}
\todo{This is ingenious and fucking important, read and correct multiple times}
A more general approach to improving the retrieved dataset is to introduce
ambiguity. The developer may be more familiar with the structure of the dataset
passed to the template engine than the structure of the template, which dictates
the structure of the dataset retrieved from the rendered template.

When a section intended as an if block is retrieved from the rendered template
the client library returns an array regardless of the amount of iterations the
section has performed\footnote{
	not accounting for effects of the modification proposed in \ref{sec:flatten-section}
} (which in the case of if blocks should be zero or one).
Since the original dataset held a single object at that position,
the developer will not expect to find an array.

Our tool has no way of determining the semantic meaning of a section in a
template.
Fortunately we do not need to be certain what the intended usage of the section
is to rebuild the original dataset structure.
If a section iterated only once we can decorate the resulting array with every
property of the first entry in the array. Whichever version the developer
expected, he will now be able to access it that way. This approach will however
not work when there are no iterations since we cannot let a key in our dataset
be both an empty list and the value false\footnote{
	\inline{\!\![]} returns true instead of false unfortunately (in our use-case)
}. This means the user will not be able to check for the existence of an object.

\todo{Highlight the idiocy of actually deleting a variable mapping after converting it to an array}

We can continue improving the dataset by introducing even more ambiguity.
Our tool does not know at which context stack level an identifier originates,
this can lead to the tool situating values in the wrong place in the retrieved
dataset. We can alleviate this by propagating these values upwards as long as no
conflicting identifier values are encountered. We can do this in the case of a
section with a single iteration and with values that remain constant through all
section iterations.

This propagation can however introduce values to sections where the identifier
did not originate from. Apart from this inaccuracy we may also supply the user
with false values. The original dataset can contain values, which are unused in
the template. This means we will not be able to recognize all conflicts when
propagating.

\section{Future Work}

\subsection{Modifying rendered templates}
\label{sec:update-dom}
The \inline{update()} function\footnote{section \ref{sec:update}} returned by
variables is helpful when the developer intends to update strings in the
template. In \ref{sec:loopbacking} we demonstrated how our demo application
could ``push'' and ``pop'' iterations onto and from a dataset and then re-render
the template with the new values to display the changes.
This re-rendering performs a lot of unnecessary work considering it is only
the rendered template content of one section that needs to be appended or
removed.

If our pre-parser tool were to extract the template content of a section, we
could append an additional iteration by only rendering this content with the
newly pushed item using \emph{mustache.js}.

If we are to remove an iteration we simply remove the nodes that were recognized
as belonging to that iteration when the rendered template was parsed.

\subsection{Two-way binding of models}
After implementing \ref{sec:update-dom} layers can be constructed as
mediators between Comb and client model libraries. As an example of such a
library we will choose backbone. The backbone library features an event
architecture which allows the developer to be notified when properties of
objects change. Using this architecture we can create a tool that allows the
developer to specify which identifier in the dataset returned by Comb a
backbone model property corresponds to. Lists in the dataset may be mapped to
collections.

Once such a mapping is established, our tool can propagate changes in the models
to the DOM. Reversing this effect is also possible by listening for changes in
the DOM (e.g. a change of an input field value) and updating the mapped model
instead.

\end{document}
