\chapter{Revised Requirements}
In this chapter we will analyze which parts of our exploratory prototype we can
utilize in our next iteration. To that end we will examine every tool used and
arrive at a subset of these tools, which we will complement with a fresh set of
parts. Our goal is to have a plan laid out for the next iteration at the end of
this chapter.

The prototype featured a large amount of moving parts that were constructed for
the occasion. Among others this includes our templates, that were not mustache
templates but simple repeatable patterns in PHP. The recursive tree parser,
building a set of models and views for us to use on the client side is another
example of an ad-hoc constructed tool.

These parts bring with them their own set of problems and bugs.
Since they are custom developed in a limited time frame they will have coding
errors other seasoned related tools do not have.
Seeing how the last iteration resulted in a prototype,
we decided to develop these tools regardless,
because evaluating alternatives that would fit the purpose precisely
would have taken up more time.
This is however not a sound strategy going forward, assuming we have the goal to
develop a reliable tool to realize our concept of binding server-side templates
to client-side models.
Succinctly put: There is no reason to reinvent the wheel.
Most of these parts have nothing to do directly with the concept of this thesis.
They are rather tools that help achieve the goals of it.
For a proper tool, that we can consider usable, to emerge from our process,
we will need to reduce the amount of said custom parts.
To that end we will first have to identify the superfluous parts of the
prototype, that can be replaced by existing well maintained tools. Once we have
achieved this, we can begin concentrating on the core of our concept and define
it with greater precision.

\section{Additional requirements}
In the prototype we omitted some parts of the concept architecture by "faking"
them. This holds true especially, when we look at how the information gained
by parsing the server templates is transmitted to the client.
The information itself is hard coded into the client, meaning both the part for
parsing templates and the matter of client communication is missing.

The traversal of the DOM happened in a very limited way, where the parser was
finely tuned to parse only our specific case but nothing more.
We will have to analyze which, if any, of these gaps can be filled by generic
tools and which gaps belong to the core of our concept.

Some gaps may not even need to be filled. This will surely be the case,
when we consider that the desired end result is a tool and not a framework.
Many frameworks and tools in the prototype were used to illustrate the concept
via a demo application. There are a lot more parts needed to create a working
web-application than there are to create a tools for said application.



\section{Simplifying the project}

Bear in mind that despite the following simplifications we may still use some
of the tools. We intend our tool to perform in an ecosystem of other software,
which can integrate loosely with our tool instead of requiring deep integration
with it.

\subsection{Server-side}
We begin our simplification on the server. Here we communicated with a database
to persist our movies, actors etc. in the MySQL database. The database and the
object relational mapper (ORM) php-activerecord are not at all necessary for our
tool to work. They are interchangeable with any other type of software, that can
persist data on the server. Our concept should work with even ephemeral data.

Our server-side language of choice - PHP -, also belongs to this category.
The server could have been written in any other server-side language.
As a consequence, the template engine (mustache), will of course need to be
able to interface with that language. For the prototype we omitted these
templates and wrote them directly in PHP instead.

Our plan however is to write the server-side templates in mustache in the next
iteration.
Locating placeholders in these templates and outputting their location
is the solution we proposed in the beginning of this thesis to the problem
we identified with server side templates.
By extension parsing server side templates pertains to the core of our concept.
Since parsing arbitrary template syntaxes, would go out of the scope of this
thesis we must conclude that mustache belongs to the category of tools that
cannot be removed.

\subsection{Client-side}
The client-side tools we have used in our prototype interact with the data we
"retrieved" (remember: we did not actually retrieve any template information)
from the server. This makes the setup of the client more intricate. We will have
to look carefully at each tool and determine by the nature of its interaction
with that data, whether it is a crucial part of our concept.

Regardless of which tools we remove, we must remember that the information about
our server-side templates must be used somehow. This would suggest that the
client can have more than one structure and set of interconnected parts, which
leverage the additional information.

\begin{itemize}
\item Beginning with the periphery, we can easily see how a framework to ease
the development of CSS is not part of our tool.
\item The Javascript language is required on the basis that we need some form of
client side programming. We have discussed its alternatives earlier in this
thesis and are going to keep this choice.
\item underscore.js helps us to iterate through arrays and manage other
operations more easily than in pure Javascript. We can solve the same problems
without it (although it requires more effort). This makes underscore.js a
non-crucial part of our tool.
\item jQuery is used to retrieve the values from the DOM. We may later change
how we retrieve those values, but some method of retrieval will be needed.
At this point jQuery seems to fit the bill and we must consider jQuery a crucial
part of our tool.
\item We use backbone.js to hold the values we retrieve from the DOM. The
framework enables us to interact with these values. They can however also be
modeled with simple JavaScript objects. Because of that backbone.js can not be
considered a crucial part of our tool.
\end{itemize}

This concludes the evaluation of tools we used in our prototype. There is
still the matter of categorizing our own custom DOM traverser, which
takes a root model as input and recursively reads the nested values in the DOM.
During this traversal it also creates Models attached to corresponding
ViewModels.
Using this strategy we obtain a consistent and predictable control flow of the
initialization process. The disadvantages include rigidity in the way
the placeholder information from the server is used and a need to specify what
type of view each placeholder represents.
We desire a decentralization of responsibility and a more liberal use of
the template placeholder data. This means that we must replace the parser with
something else that is not a substitute, but a rethinking of its role in the
process of utilizing the placeholder data.

\subsection{The consequences of our simplification}

Let us summarize what these changes mean for our next iteration.

We have kept quite a few client libraries and those we deemed non-essential were
only discounted to reduce complexity.
The only client side code we decided to remove, was the one we wrote ourselves.
Similarly we removed from the server-side our ad-hoc implementation of a
template engine.
We deemed the ORM and the database backing inconsequential to our tool, although
many fully fledged web applications of course can not function without it.

These reductions leave us with a clear picture of which tools we carry over into
the next iteration.
On the server-side we will only need the mustache template engine
and our parser, which we will create in the next iteration.
On the client-side we have a collection of libraries that when combined gives us
part of the architecture that will allow us to utilize the information generated
by the server.
There are however still gaps in this architecture. We require a framework, that
allows us to organize our models and views properly. It should also support
the addition of our discarded parsing feature, by supplying a structure to bind
it to. "Chaplin" will in this case be our framework of choice.

\todo{Figure out if we want to fight the fight and call the view viewmodel}
\subsection{chaplin}
Chaplin is a new client side framework, which was created in February 2012.
The motivation behind it was to create a framework that allows developers to
follow a set of conventions more easily. Backbone.js has both views and models
(and routes, for controllers), but does not force any specific way of
structuring code. In this respect Backbone.js can be seen more as a tool than a
framework.
Chaplin extends the models and views from Backbone.js and adds more features.
It introduces concepts such as "subviews" - views that aggregate other views.
This allows the developer among other things to better mirror the structure of
the DOM.

The framework also allows the developer to use any template engine he desires.
The engine simply needs to return an object, which jQuery can append to the
wrapping DOM element of the view.

A very useful feature of Chaplin is the automatic memory management.
When creating single page web-applications, the developer has to dispose each
view manually. This challenge is best illustrated with regard to eventhandlers.
Eventhandlers are functions, that are called when an event on a DOM node or
an other object is trigger. Often this function manipulates and accesses
properties stored on a view. To allow for this access, the function stores a
pointer to the view via a closure. Since the function is stored with the
DOM node or object on which it is listening for events, any view the developer
wants to dispose needs to stop listening on those events as well.
Chaplin unbinds these eventhandlers for the developer when the view is disposed,
allowing the browser to free up memory.

The framework has however a major drawback: A view does not add subview elements
to its DOM tree by means of the template function. Instead the developer
must use jQuery to append these elements to an element in the DOM.
Supposing that these subview elements are not attached directly beneath the root
element of the view, the developer will need to traverse parts of the DOM tree
with a jQuery selector to find the correct position to attach a subview element.
This breaks the fundamental principle of dividing the view(-model) from the
template data. A view now has to hold information about the layout of the DOM,
it is hard-coded into the view.

Our tool can solve this problem by supplying the view with those selectors.
The only requirement would be that the developer wrote placeholders into the
templates that identified subviews of the corresponding view.
The view can use the selectors generated for those placeholders
to pinpoint the exact location where a subview element should be attached.

A quicker solution to this problem would be to insert these placeholders and
modify the template engine to understand the concept of subviews.
Unfortunately there is a major drawback to that strategy.
Every subview will be inserted into the DOM when the parent view is rendered,
even though the developer may wish to delay that insertion.
Also, the attachment of subviews that are yet to be created requires a
rerendering of the entire DOM sub-tree.

We intend to modify Chaplin to take advantage of these placeholder selectors
automatically. The developer should not be required to interact with the
selectors.

\subsection{Data types}
In the first iteration we not only retrieved the values located in the DOM but
also specified what types these values were. In fact, retrieving data from the
DOM and mapping data fields to types are two very different processes. We will
not try to map data to types or Models in the next iteration, it would exceed
the scope of our tool and expose the user to a layer of abstraction that may not
be desired.

In section \ref{sec:first:results} of chapter \ref{chap:first} we
recognized the need for knowing the types of data.
This is not in conflict with this decision, we are still interested in
knowing when data (or rather a mustache tag) behaves recursively, so that we may
take appropriate steps to parse a rendered template accordingly. This holds true
specifically for mustache partials, which can refer to the template they are
specified in.

Removing the data typing feature may still reduce the immediate usefulness
of our tool. The removal increases the applicability of it however.
A mapping layer may still be put on top of our tool to abstract raw data
into backbone models.
Such a mapping layer could also be a form validation tool or a custom
data model to abstract a very specific use case.
This way we construct a tool instead of a framework.




\todo{What about our initial goal, reading the information from the DOM}
\todo{What about not rerendering ANYTHING? modelbind changes and replace the corresponding nodes}
